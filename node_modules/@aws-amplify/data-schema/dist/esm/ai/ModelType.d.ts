declare const supportedModelsLookup: {
    readonly 'Claude 3 Haiku': "anthropic.claude-3-haiku-20240307-v1:0";
    readonly 'Claude 3 Opus': "anthropic.claude-3-opus-20240229-v1:0";
    readonly 'Claude 3 Sonnet': "anthropic.claude-3-sonnet-20240229-v1:0";
    readonly 'Claude 3.5 Sonnet': "anthropic.claude-3-5-sonnet-20240620-v1:0";
    readonly 'Cohere Command R': "cohere.command-r-v1:0";
    readonly 'Cohere Command R+': "cohere.command-r-plus-v1:0";
    readonly 'Llama 3.1 8B Instruct': "meta.llama3-1-8b-instruct-v1:0";
    readonly 'Llama 3.1 70B Instruct': "meta.llama3-1-70b-instruct-v1:0";
    readonly 'Llama 3.1 405B Instruct': "meta.llama3-1-405b-instruct-v1:0";
    readonly 'Mistral Large': "mistral.mistral-large-2402-v1:0";
    readonly 'Mistral Large 2': "mistral.mistral-large-2407-v1:0";
    readonly 'Mistral Small': "mistral.mistral-small-2402-v1:0";
};
export interface AiModel {
    resourcePath: string;
}
export interface InferenceConfiguration {
    topP?: number;
    temperature?: number;
    maxTokens?: number;
}
/**
 * @experimental
 *
 * Bedrock models currently supporting Converse API and Tool use
 * @see {@link https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features}
 */
export declare function model(modelName: keyof typeof supportedModelsLookup): AiModel;
export {};
